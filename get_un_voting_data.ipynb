{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d3157a-becc-4e0d-8a43-1568da875d0f",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "* get rid of requests we don't use\n",
    "* annotate the code to explain what we're doing and why [tutorial!]\n",
    "* have to explain what broad categories we wanted to analyze and why\n",
    "    * clean up our doc about what categories we want to use and add it to the github, explain why we are only using certain [un] categories for now (most bang for our buck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d1d6d-d43c-4fc3-a3c6-1cb7ad1980ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff6755-13cf-4fe3-a739-e9e2878a589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_links_df = pd.read_csv('category-links.csv')\n",
    "category_links_df\n",
    "\n",
    "visited_categories = []\n",
    "resolution_urls = list()\n",
    "total_resolutions = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed82f4-298a-4860-aced-23a159ca6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res_links_from_page(page_link, total_resolutions):\n",
    "    \n",
    "    links = []\n",
    "    \n",
    "    page = requests.get(page_link)\n",
    "    if page.status_code != 200:\n",
    "        raise Exception(\"Something went wrong loading category: \" + category + \", error code: \" + page.status_code)\n",
    "\n",
    "    html = page.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    resolution_cnt = int(soup.find(\"strong\", {\"class\": None}).text)\n",
    "\n",
    "    if resolution_cnt > 50:\n",
    "        if resolution_cnt%50 == 0:\n",
    "            page_count = (int) (resolution_cnt/50)\n",
    "        else: page_count = int((resolution_cnt/50) + 1)\n",
    "    else: page_count = 1\n",
    "\n",
    "    for page in range(page_count):\n",
    "\n",
    "        for div in soup.find_all(\"div\", {\"class\": \"moreinfo\"}):\n",
    "            res_link_suffix = div.find(\"a\")[\"href\"]\n",
    "            links.append('https://digitallibrary.un.org' + res_link_suffix)\n",
    "\n",
    "        time.sleep(10)\n",
    "\n",
    "        #load the next page if you're not already on the last page (0 indexing)\n",
    "        if (page+1 != page_count):\n",
    "            next_page_link_suffix = soup.find(\"span\", {\"class\": \"rec-navigation\"}).findAll(\"a\")[-1][\"href\"]\n",
    "            next_page_link = 'https://digitallibrary.un.org' + next_page_link_suffix\n",
    "            #print(page)\n",
    "            #print(next_page_link)\n",
    "\n",
    "            page = requests.get(next_page_link)\n",
    "            if page.status_code != 200:\n",
    "                raise Exception(\"Something went wrong loading next page, error code: \" + page.status_code)\n",
    "\n",
    "            html = page.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "        \n",
    "    if (total_resolutions + resolution_cnt != len(links)):\n",
    "        raise Exception(\"resolution count does not match\")\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fcd568-effa-4678-b05a-b04c711c8a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get the initial website with the categories\n",
    "for cat, link in zip (category_link_df[\"un category\"], category_link_df[\"link\"]):\n",
    "    if (cat not in visited_categories):\n",
    "        try:\n",
    "            cat_res_links = get_res_links_from_page(page_link, total_resolutions) #grab the links, may throw an exception\n",
    "            resolution_urls.extend(cat_res_links) #append the new links list to the bigger old links list\n",
    "            total_resolutions = len(resolution_urls) #update total resolution count for next runthrough\n",
    "            visited_categories.append(cat)\n",
    "        except:\n",
    "            print(\"oh no the UN blocked you maybe :(\")\n",
    "        finally:\n",
    "            time.sleep(3) #delay to hopefully prevent the un from detecting and blocking us\n",
    "\n",
    "#write results to file\n",
    "textfile = open(\"res_links.txt\", \"w\")\n",
    "for res_url in resolution_urls:\n",
    "    textfile.write(res_url + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff75b4b-df2c-46e2-99f0-329b00b6f545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## get unique resolutions => THIS DOES NOT WORK????????????\n",
    "# len(np.unique(resolution_urls))\n",
    "\n",
    "#Make resolution_urls unique\n",
    "def unique(list1):\n",
    "    # initialize a null list\n",
    "    unique_list = []\n",
    "     \n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    return unique_list\n",
    "\n",
    "# ex of function use in next line\n",
    "#unq_res_urls = unique(resolution_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91104853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get vote data from each resolution\n",
    "\n",
    "#resolution df (x= index, y = name, year)\n",
    "#country_votes df (row = country, col= resolution indices) row,col = vote\n",
    "\n",
    "resolutions\n",
    "for res_url in unq_res_urls:\n",
    "    res_page = requests.get(res_url)\n",
    "    if res_page.status_code != 200:\n",
    "        raise Exception(\"Something went wrong loading resolution, error code: \" + res_page.status_code)\n",
    "        \n",
    "    html = res_page.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    metadata = soup.find_all(\"span\", {\"class\": \"value col-xs-12 col-sm-9 col-md-10\"})\n",
    "\n",
    "    #number of metadata sections changes from resolution to resolution, so start counting from bottom for some\n",
    "    res_title = metadata[0] \n",
    "    #res_title.text\n",
    "    vote_summary = metadata[len(metadata) -4]\n",
    "    vote_date = metadata[len(metadata) -3]\n",
    "    vote = metadata[len(metadata) -2]\n",
    "    time.sleep(10) #can change later\n",
    "    \n",
    "    #STORE THIS INFO IN DF EACH TIME"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
